{
  "hash": "369f98876e632793403be93e1199134c",
  "result": {
    "markdown": "---\nexecute: \n  echo: true\n  eval: false\n  warning: false\n---\n\n\n# Creating the Soybean Expression Atlas v2\n\nHere, I will describe the code I used to create the Soybean Expression \nAtlas using the R package *bears*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) # for reproducibility\n\n# Load required packages\nlibrary(here)\nlibrary(bears)\nlibrary(tidyverse)\n```\n:::\n\n\n## Downloading data\n\nWe will download samples that have not been downloaded yet. The data frames \nwith sample metadata are stored in the `data/` directory. \n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(timeout = 1e+10)\n\n#----Get sample metadata--------------------------------------------------------\nterm <- \"Glycine max[ORGN] AND RNA-seq[STRA]\"\nmetadata_all <- create_sample_info(term, retmax = 10000)\n\n# Remove unsupported technologies\nmetadata_all <- metadata_all[!grepl(\n    \"454|SOLiD|PacBio|Torrent|AB 310|Complete Genomics|ION\", \n    metadata_all$Instrument\n), ]\n\n## Save metadata object\nsave(\n    metadata_all,\n    file = here(\"data\", \"metadata_all.rda\"),\n    compress = \"xz\"\n)\n\n## Create directory structure\nrootdir <- here(\"results\")\nds <- create_dir_structure(rootdir = rootdir)\nsave(ds, file = here(\"data\", \"ds.rda\"), compress = \"xz\")\n\n#----Downloading samples----------------------------------------------------\nurls <- get_url_ena(metadata_all)\ndownload <- download_from_ena(urls = urls, fastqdir = ds$fastqdir)\n```\n:::\n\n\nNow, let's check the file integrity of downloaded files. Here, I will do\nit for the whole atlas, including previous versions, just as a sanity check.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#----Check file integrity with md5sum check-------------------------------------\n\n# Remove runs that were not downloaded\ndownloaded <- fastq_exists(metadata_all, fastqdir = ds$fastqdir)\ndownloaded <- downloaded$Run[!is.na(downloaded$Status)]\nmetadata_atlas_v2 <- metadata_all[metadata_all$Run %in% downloaded, ]\n\n## Check md5sum\nintegrity <- check_md5(\n    run_accessions = metadata_all$Run, \n    fastqdir = ds$fastqdir\n)\n\nfailed_corrupt <- integrity[integrity$Status == FALSE, \"Run\"]\nfailed_corrupt <- unique(as.character(failed_corrupt))\n```\n:::\n\n\nThe `failed_corrupt` object is a character vector containing run accessions that\nfailed the integrity check and, thus, must be re-downloaded. \nNow, let's also check for files that were not downloaded at all. Here, we will \nonly consider for re-download runs that are part of BioProjects with \neffectively downloaded runs. In other words, if all runs of a BioProject were \nnot downloaded, I will ignore them (they are probably not available on EBI).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get download status\ndstatus <- fastq_exists(metadata_all, fastqdir = ds$fastqdir)\n\n# Get BioProject info of failed runs\nfailed_bioproject <- dstatus %>%\n    full_join(., metadata_all)\n\n# Get BioProjects with missing percentage (m) = 0 < m < 100\nbioprojects_download <- failed_bioproject %>%\n    group_by(BioProject) %>%\n    summarise(perc = sum(is.na(Status)) / length(BioProject)) %>%\n    filter(perc != 0 & perc != 1)\n\n\n# Get vector of runs from these BioProjects to re-download\nfailed_nd <- failed_bioproject %>%\n    filter(is.na(Status) & BioProject %in% bioprojects_download$BioProject) %>%\n    select(Run)\n\nfailed_nd <- unique(as.character(failed_nd$Run))\n```\n:::\n\n\nIn the end, 33 runs failed the integrity check (i.e., they were downloaded,\nbut md5sums were different from the reference), and 33 runs failed to\ndownload (i.e., some runs from the BioProject were downloaded, but others were\nnot). Re-downloading failed runs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Metadata data frame of failed runs only\ntodownload <- c(failed_corrupt, failed_nd)\nmetadata_failed <- metadata_all[metadata_all$Run %in% todownload, ]\n\n# Download again\nurls_missing <- get_url_ena(metadata_failed)\n\noptions(timeout = 1e10)\ndownload_missing <- download_from_ena(\n    metadata_failed,\n    urls = urls_missing, \n    fastqdir = ds$fastqdir\n)\n```\n:::\n\n\nDone! Finally, let's create a final metadata data frame with all samples we have:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndstatus <- fastq_exists(metadata_all, fastqdir = ds$fastqdir)\nok_runs <- unique(dstatus$Run[dstatus$Status == \"OK\"])\n\nmetadata_atlas_v2 <- metadata_all[metadata_all$Run %in% ok_runs, ]\n\n## Save a data frame containing metadata for all samples of SEA v2\nsave(\n    metadata_atlas_v2_downloaded,\n    file = here::here(\"data\", \"metadata_atlas_v2_downloaded.rda\"),\n    compress = \"xz\"\n)\n```\n:::\n\n\n## Sequence QC and filtering\n\nNow, we will remove sequence adapters and low-quality bases with __fastp__.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmetadata_atlas_v2 <- metadata_atlas_v2_downloaded\n\nruns_fastp <- fastq_exists(metadata_atlas_v2, ds$fastqdir) %>%\n    dplyr::filter(!is.na(Status)) %>%\n    dplyr::pull(Run)\n\nmetadata_fastp <- metadata_atlas_v2[metadata_atlas_v2$Run %in% runs_fastp, ]\n\n# Run fastp\nfastp_status <- trim_reads(\n    metadata_fastp, \n    fastqdir = ds$fastqdir, \n    filtdir = ds$filtdir,\n    qcdir = ds$qcdir,\n    threads = 16,\n    delete_raw = TRUE\n)\n\n# Get a metadata data frame with only reads that have undergone filtering\nfiltered_reads <- unique(\n    gsub(\n        \"(\\\\.fastq.*)|(_.*)\", \"\", \n        basename(list.files(ds$filtdir, pattern = \"fastq.gz\"))\n    )\n)\n\nmetadata_atlas_v2_filtered <- metadata_atlas_v2[\n    metadata_atlas_v2$Run %in% filtered_reads, \n]\n\nsave(\n    metadata_atlas_v2_filtered, compress = \"xz\",\n    file = here(\"data\", \"metadata_atlas_v2_filtered.rda\")\n)\n```\n:::\n\n\nNow, let's import and save read filtering stats.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get a data frame of summary stats from fastp\nfastp_stats <- summary_stats_fastp(ds$qcdir)\n\nsave(\n    fastp_stats, compress = \"xz\",\n    file = here(\"products\", \"result_files\", \"fastp_stats.rda\")\n)\n```\n:::\n\n\nFinally, we will remove low-quality files based on the following criteria:\n\n1. Mean length after filtering < 40\n2. Q20 rate <80% after filtering.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove files whose mean length after filtering is <40 and Q20 <80%\nkeep <- fastp_stats %>%\n    filter(after_meanlength >= 40) %>% \n    filter(after_q20rate >= 0.8) %>%\n    pull(Sample)\n\nfiltered_metadata <- metadata_atlas_v2_filtered[\n    metadata_atlas_v2_filtered$Run %in% keep, \n]\nrownames(filtered_metadata) <- 1:nrow(filtered_metadata)\n```\n:::\n\n\n## Quantifying transcript abundance\n\nNext, we will quantify transcript abundance with __salmon__. To do that, \nwe first need to index the reference transcriptome.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Index transcriptome\ntranscriptome_path <- here(\"data\", \"gmax_transcriptome.fa.gz\")\n\nidx_salmon <- salmon_index(\n    salmonindex = ds$salmonindex,\n    transcriptome_path = transcriptome_path\n)\n\nidx_salmon\n```\n:::\n\n\nThen, we can quantify transcript abundance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Quantify transcript abundance\nquant_salmon <- salmon_quantify(\n    filtered_metadata,\n    filtdir = ds$filtdir,\n    salmonindex = ds$salmonindex,\n    salmondir = ds$salmondir,\n    threads = 40\n)\n\n# Checking percentage of samples that ran sucessfully\nn_ok <- nrow(quant_salmon[!is.na(quant_salmon$status), ])\nn_ok / nrow(quant_salmon)\n```\n:::\n\n\n__salmon__ was run sucessfully for 100% of the samples. Great! Now, let's obtain\nmapping rates for each BioSample to see whether or not we need to discard \nsamples. Here, we will remove samples with mapping rate <50% (i.e., less than\n50% of the reads failed to \"map\").\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get a data frame of mapping rate per BioSample\nbiosamples <- unique(filtered_metadata$BioSample)\nmapping_rate <- summary_stats_salmon(ds$salmondir, biosamples)\n\nsave(\n    mapping_rate, compress = \"xz\",\n    file = here(\"products\", \"result_files\", \"mapping_rate_salmon.rda\")\n)\n\n# Removing BioSamples with mapping rate <50%\nbiosamples_to_keep <- mapping_rate %>%\n    filter(Mapping_rate >= 50) %>%\n    pull(BioSample)\n\n# Update metadata data frame to keep only samples that passed the filtering step\nfinal_metadata_atlas_v2 <- filtered_metadata %>%\n    filter(BioSample %in% biosamples_to_keep)\n```\n:::\n\n\n82% of the samples (5481/6644) passed the filtering step (i.e., \nhad mapping rates >=50%). Thus, this is the final number of samples in the\nSoybean Expression Atlas v2. \n\nTo conclude, let's just fix and standardize tissue names in the \nmetadata data frame and save it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_metadata_classified_tissues <- final_metadata_atlas_v2 %>% \n    mutate(Tissue_PO = str_to_lower(Tissue)) %>%\n    mutate(Tissue_PO = str_replace_all(\n        Tissue_PO,\n        c(\".*nodule.*\" = \"nodule\",\n          \".*leaves and roots.*\" = \"whole plant\",\n          \".*leaves.*\" = \"leaf\",\n          \".*leaf.*\" = \"leaf\",\n          \".*trifoliate.*\" = \"leaf\",\n          \".*seed coat.*\" = \"seed coat\",\n          \".*crown.*\" = \"root\",\n          \".*shoot.*\" = \"shoot\",\n          \".*stem.*\" = \"shoot\",\n          \".*hypocotyl.*\" = \"hypocotyl\",\n          \".*pod.*\" = \"pod\",\n          \".*root.*\" = \"\",\n          \".*embryo.*\" = \"embryo\",\n          \".*seedling.*\" = \"seedling\",\n          \".*cytoledon.*\" = \"cotyledon\",\n          \".*cotyledon.*\" = \"cotyledon\",\n          \".*seed.*\" = \"seed\",\n          \".*flower.*\" = \"flower\",\n          \".*petiole.*\" = \"petiole\",\n          \".*meristem.*\" = \"meristem\",\n          \".*radicle*\" = \"radicle\",\n          \".*epicotyl.*\" = \"epicotyl\",\n          \".*whole.*\" = \"whole plant\",\n          \".*roots + leaves.*\" = \"whole plant\",\n          \".*sprout*\" = \"seedling\",\n          \".*ovule.*\" = \"flower\",\n          \".*suspensor*\" = \"suspensor\",\n          \".*floral.*\" = \"flower\",\n          \".*leaf bud.*\" = \"leaf\",\n          \".*anther*\" = \"flower\",\n          \".*stem and leaf*\" = \"whole plant\",\n          \".*ovary.*\" = \"flower\",\n          \".*embryo.*\" = \"embryo\",\n          \".*embryo.*\" = \"embryo\",\n          \".*embryo.*\" = \"embryo\"\n        )\n    )\n    )\n\nwrite_tsv(\n    final_metadata_classified_tissues, \n    file = here(\"products\", \"tables\", \"final_metadata_classified_tissues.tsv\")\n)\n```\n:::\n\n\nThe file *final_metadata_classified_tissues.tsv* was manually edited to include\nclassifications for missing tissues, and then it was renamed to \n*final_metadata_classified_atlas_v2.tsv*. This file only contains \nBioSample-level information (runs were not considered).\n\n## Session information {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.0 (2023-04-21)\n os       Ubuntu 20.04.5 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Brussels\n date     2023-06-23\n pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli           3.6.1   2023-03-23 [1] CRAN (R 4.3.0)\n digest        0.6.31  2022-12-11 [1] CRAN (R 4.3.0)\n evaluate      0.20    2023-01-17 [1] CRAN (R 4.3.0)\n fastmap       1.1.1   2023-02-24 [1] CRAN (R 4.3.0)\n htmltools     0.5.5   2023-03-23 [1] CRAN (R 4.3.0)\n htmlwidgets   1.6.2   2023-03-17 [1] CRAN (R 4.3.0)\n jsonlite      1.8.4   2022-12-06 [1] CRAN (R 4.3.0)\n knitr         1.42    2023-01-25 [1] CRAN (R 4.3.0)\n rlang         1.1.1   2023-04-28 [1] CRAN (R 4.3.0)\n rmarkdown     2.21    2023-03-26 [1] CRAN (R 4.3.0)\n rstudioapi    0.14    2022-08-22 [1] CRAN (R 4.3.0)\n sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.3.0)\n xfun          0.39    2023-04-20 [1] CRAN (R 4.3.0)\n yaml          2.3.7   2023-01-23 [1] CRAN (R 4.3.0)\n\n [1] /home/faalm/R/x86_64-pc-linux-gnu-library/4.3\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}